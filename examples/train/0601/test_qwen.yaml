# model
#model_name_or_path: /mnt/e/UbuntuFiles/models_saved/Qwen1.5-14B-Chat-GPTQ-Int4
model_name_or_path: /mnt/d/PycharmProjects/models/Qwen1.5-14B-Chat-GPTQ-Int4
#adapter_name_or_path: /mnt/e/dxy/LLaMA-Efficient-Tuning/checkpoints/qwen/0513_qwen_rag_exp1
#finetuning_type: lora

# method
stage: sft
do_predict: true
#finetuning_type: lora

# dataset
dataset: alpaca_zh_demo
template: qwen
cutoff_len: 512
max_samples: 2
overwrite_cache: true
preprocessing_num_workers: 16

# output
output_dir: checkpoints/qwen/qwen_vanilla/
overwrite_output_dir: true

# eval
per_device_eval_batch_size: 1
predict_with_generate: true
